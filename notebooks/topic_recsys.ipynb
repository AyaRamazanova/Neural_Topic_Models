{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендация статей с помощью тематических моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "arxiv_tokens = OrderedDict()\n",
    "with open('data/arxiv_plain.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        cur_tokens = line.split()\n",
    "        arxiv_tokens[cur_tokens[0]] = cur_tokens[1:]\n",
    "arxiv_titles = list(arxiv_tokens.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43091"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arxiv_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel, CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "arxiv_dictionary = Dictionary(list(arxiv_tokens.values()))\n",
    "arxiv_corpus = [arxiv_dictionary.doc2bow(text) for text in list(arxiv_tokens.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(arxiv_corpus, num_topics=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0.08792581),\n",
       " (6, 0.44382215),\n",
       " (10, 0.029720737),\n",
       " (15, 0.06753212),\n",
       " (26, 0.06441488),\n",
       " (28, 0.29692042)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_document_topics(arxiv_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43091it [03:12, 223.64it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "theta = {}\n",
    "for doc_title, doc_bow in tqdm.tqdm(zip(arxiv_titles, arxiv_corpus)):\n",
    "    topic_vector = np.zeros(lda.num_topics)\n",
    "    for topic_num, topic_prob in lda.get_document_topics(doc_bow):\n",
    "        topic_vector[topic_num] = topic_prob\n",
    "    theta[doc_title] = topic_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тематический вектор статьи с номером 0704.0004:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.08794806, 0.44381464, 0.        , 0.        , 0.        ,\n",
       "       0.02972036, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.067536  , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.0643954 , 0.        , 0.29690889, 0.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta['0704.0004']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь для того, чтобы порекомендовать читателю близкие по смыслу статьи, достаточно выбрать метрику близости и сравнить вектор текущего документа (например, последнего прочитанного) с векторами всех остальных документов в коллекции. В качестве метрики близости можно использовать косинусную меру, евклидово расстояние, расстояние Хелингера и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def cos_sim(first, second):\n",
    "    return metrics.pairwise.cosine_similarity(first.reshape(1, -1), second.reshape(1, -1))[0][0]\n",
    "\n",
    "def dot_sim(first, second):\n",
    "    return first.dot(second)\n",
    "\n",
    "def hel_sim(first, second): #one more sqrt and division by sqrt(2) omitted, minus added\n",
    "    return -np.sum((np.sqrt(first) - np.sqrt(second)) ** 2)\n",
    "\n",
    "def jaccard_sim(first, second):\n",
    "    intersection = set(first).intersection(set(second))\n",
    "    union = set(first).union(set(second))\n",
    "    return float(len(intersection))/float(len(union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_papers(query, theta, sim=cos_sim, top_k=10):\n",
    "    query_vec = theta[query]\n",
    "    ranked_list = []\n",
    "    for doc_name, doc_vec in theta.items():\n",
    "        ranked_list.append((doc_name, sim(query_vec, doc_vec)))\n",
    "    ranked_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    return ranked_list[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_papers = recommend_papers('0704.2596', theta, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0704.2596\n",
      "codes code minimum weight linear information using gr obner compute\n",
      "\n",
      "0904.3148\n",
      "bch long gf deg code parallel architecture polynomial lfsr encoding\n",
      "\n",
      "1008.1498\n",
      "matrix sparse null vector sparsification approximation problem space problems min\n",
      "\n",
      "1111.4301\n",
      "encryption homomorphic key our will scheme error every circuit kq\n",
      "\n",
      "1401.1876\n",
      "wg power optimal wch flow bus relaxation opf matrix r2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for paper_name, prob in recommended_papers:\n",
    "    print(paper_name)\n",
    "    print(' '.join([token[0] for token in Counter(arxiv_tokens[paper_name]).most_common(10)]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества полученной рекомендательной системы воспользуемся датасетом триплетов [[Dai et al. 2015](https://arxiv.org/abs/1507.07998)]. Датасет содержит тройки статей `<запрос>|<релевантная статья>|<нерелевантная статья>`. Будем считать, что если метрика близости между запросом и релевантной статьей оказалась выше, чем между запросом и нерелевантной статьей, то такая тройка обработана \"правильно\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_quality(theta, sim):\n",
    "    all_triplets = 0\n",
    "    covered_triplets = 0\n",
    "    correct_triplets = 0\n",
    "    with open('data/arxiv_triplets.txt', 'r') as fin:\n",
    "        for line in fin:\n",
    "            ids = list(map(lambda x: x.split('/pdf/')[-1], line.split()))\n",
    "            if all([x in theta.keys() for x in ids]):\n",
    "                covered_triplets += 1\n",
    "                vectors = [theta[x] for x in ids]\n",
    "                correct_triplets += sim(vectors[0], vectors[1]) > sim(vectors[0], vectors[2])\n",
    "            all_triplets += 1\n",
    "\n",
    "    return 1.0 * correct_triplets / covered_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851889232321958"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_quality(theta, cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8640005046363465"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_quality(theta, hel_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8463382325111967"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_quality(theta, dot_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперимент №2: использовать BERT-based фичи совместно с тематическими фичами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT: http://jalammar.github.io/illustrated-bert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_research env",
   "language": "python",
   "name": "py3_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
